@page "/chat"

@using System.Collections.Generic
@using Microsoft.Extensions.Options;
@using HopLind.OpenAIService
@using HopLind.OpenAIService.Models

@inject IJSRuntime JSRuntime
@inject HopLind.OpenAIService.OpenAIService OpenAIService
@inject IOptions<HopLind.OpenAIService.Config> OpenAIConfig

<PageTitle>Chat</PageTitle>

<h1>Chat</h1>

<div style="margin-bottom: 1rem">
    Advanced Settings
    <button class="btn" title="Show" onclick="toggleAdvancedSettings(this)">
        <i class="fa-regular fa-square-caret-down"></i>
    </button>
    <div id="advancedSettings" data-display="0" style="display: none">
        <div id="speechSynthesis" style="@(SupportSpeechSynthesis ? string.Empty : "display: none")">
            <label for="voices">Speaking voices:</label><select id="voices"></select>
            <div>
                <label for="rate">Speaking rate:</label><input type="range" min="0.5" max="2" value="1" step="0.1" id="rate" onchange="document.querySelector('#rate-value').textContent = document.querySelector('#rate').value" />
                <div id="rate-value" style="display: inline">1</div>
            </div>
        </div>
        <div style="border: 1px solid #ddd; margin: 1rem 0"></div>
        <div id="GPTParameters">
            <div>
                <label for="ChatContextLength">Include last messages <i class="fa-solid fa-circle-info" title="both users' inquiries and system responses"></i></label>
                <input type="range" min="2" max="10" step="2" id="ChatContextLength" @bind-value="@ChatContextLength" />
                <div id="ChatContentLength-value" style="display: inline">@ChatContextLength</div>
            </div>

            <div>
                <label for="MaxTokens">
                    Max Tokens <i class="fa-solid fa-circle-info" title="The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length."></i>
                </label>
                <input type="range" min="1" max="4000" step="1" id="MaxTokens" @bind-value="@MaxTokens" />
                <div id="MaxTokens-value" style="display: inline">@MaxTokens</div>
            </div>

            <div>
                <label for="Temperature">
                    Temperature <i class="fa-solid fa-circle-info" title="Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. Generally recommend altering this or top_p but not both."></i>
                </label>
                <input type="range" min="0" max="2" step="0.01" id="Temperature" @bind-value="@Temperature" />
                <div id="Temperature-value" style="display: inline">@Temperature</div>
            </div>

            <div>
                <label for="TopP">
                    Top P <i class="fa-solid fa-circle-info" title="An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. Generally recommend altering this or temperature but not both."></i>
                </label>
                <input type="range" min="0" max="1" step="0.01" id="TopP" @bind-value="@TopP" />
                <div id="TopP-value" style="display: inline">@TopP</div>
            </div>
        </div>
        <div>
            <label for="TechDetails">Display technical details</label>
            <input type="checkbox" id="TechDetails" @bind-value="@DisplayTechDetails" />
        </div>
        <div style="border: 1px solid #ddd; margin: 1rem 0"></div>
        <div>
            <label for="SystemMessage">
                System message (Cannot be modified during a conversation and can be reset when conversation is cleared)
                <i class="fa-solid fa-circle-info" title="The system message is included at the beginning of the prompt and is used to prime the model with context, instructions, or other information relevant to your use case. You can use the system message to describe the assistant's personality, define what the model should and shouldn't answer, and define the format of model responses."></i>
            </label>
            <br />
            <textarea id="SystemMessage" maxlength="100" style="width: 80%" disabled="@(ChatEntries.Count > 0)" @bind="@SystemMessage" />
        </div>
    </div>
</div>

<ul style="width: 100%; max-height: 70vh; padding-left: 0; overflow-y: scroll">
    @foreach (var ChatEntry in ChatEntries.Where(c => c.Role != ChatGPTRole.System))
    {
        <li style="width: 100%; margin-bottom: 0.5rem; display: flex">
            <div class="chat-role chat-@(ChatEntry.Role.ToString())">
                <img src="@($"https://api.multiavatar.com/{(ChatEntry.Role == ChatGPTRole.User ? string.Empty : "ChatGPT")}{UserUUID}.png")" width="48" />
            </div>
            <div class="chat-content chat-@(ChatEntry.Role.ToString())">
                <div id="@(Guid.NewGuid().ToString("N"))" class="markdown-raw">@(ChatEntry.Content)</div>
                <div class="markdown-container"></div>
            </div>
        </li>
    }
</ul>

<data id="markdown-is-rendering" value="@ChatIsRendering" />

<div style="width: 100%">
    <div style="color: red; display: @(ErrorShow ? "block": "none")">@ErrorMessage</div>
    <div style="display: @(DisplayTechDetails ? "block" : "none")">@TechDetails</div>
    <EditForm Model="ChatInput" style="display: flex">
        <InputTextArea style="flex: 1 1 80%;" id="ChatInput" @bind-Value="ChatInput" @oninput="SetButton" />
        <div style="width: 20%; margin-left: 0.5rem; flex: 1 1 20%">
            <button class="btn btn-primary" style="margin-right: 0.5rem; margin-bottom: 0.5rem;" title="Send" disabled="@ChatDisabled" @onclick="async () => await AddChatEntry()">
                <i class="fa-solid fa-lg fa-paper-plane"></i>
            </button>
            <button class="btn btn-primary" style="margin-right: 0.5rem; margin-bottom: 0.5rem;" title="Voice Input" hidden="@(!SupportSpeechRecognition)" disabled="@(ChatIsRequesting || ChatIsRendering == 1)" onclick="startRecognition('ChatInput')">
                <i class="fa-solid fa-lg fa-microphone-lines"></i>
            </button>
            <button class="btn btn-outline-secondary" style="margin-right: 0.5rem; margin-bottom: 0.5rem;" title="Go to Top" onclick="document.querySelector('#markdown-is-rendering').parentNode.querySelector('ul').scrollTop = 0">
                <i class="fa-regular fa-lg fa-circle-up"></i>
            </button>
            <button class="btn btn-outline-danger" style="margin-right: 0.5rem; margin-bottom: 0.5rem;" title="Clear conversation" disabled="@(ChatIsRequesting || ChatIsRendering == 1)" @onclick="() => ClearChatEntries()">
                <i class="fa-regular fa-lg fa-trash-can"></i>
            </button>
        </div>
    </EditForm>
</div>

@code {
    private string UserUUID { get; set; } = Guid.NewGuid().ToString("N");

    private bool SupportSpeechRecognition { get; set; }
    private bool SupportSpeechSynthesis { get; set; }

    private bool ErrorShow { get; set; }
    private string ErrorMessage { get; set; } = string.Empty;

    private bool ChatDisabled { get; set; } = true;
    private bool ChatIsRequesting { get; set; }
    private int ChatIsRendering { get; set; }

    private string ChatInput { get; set; } = string.Empty;

    private List<(ChatGPTRole Role, string Content)> ChatEntries { get; } = new();

    // GPT parameters
    private int ChatContextLength { get; set; } = 10;
    private int MaxTokens { get; set; } = 800;
    private decimal Temperature { get; set; } = 1;
    private decimal TopP { get; set; } = 1;

    private bool DisplayTechDetails { get; set; }
    private string TechDetails { get; set; }

    private string SystemMessage { get; set; }

    protected override async Task OnInitializedAsync()
    {
        var ChatReference = DotNetObjectReference.Create(this);
        _ = JSRuntime.InvokeVoidAsync("SetDotnetReference", ChatReference);

        await base.OnInitializedAsync();
    }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (firstRender)
        {
            SupportSpeechRecognition = await JSRuntime.InvokeAsync<bool>("getAccessibility", "SpeechRecognition");
            SupportSpeechSynthesis = await JSRuntime.InvokeAsync<bool>("getAccessibility", "SpeechSynthesis");
            _ = JSRuntime.InvokeVoidAsync("renderVoiceList");
            StateHasChanged();
        }
        await base.OnAfterRenderAsync(firstRender);
    }

    private void SetButton(ChangeEventArgs e)
    {
        ChatDisabled = ChatIsRequesting || ChatIsRendering == 1 || ((string)e.Value).Length == 0;
        StateHasChanged();
    }

    private async Task AddChatEntry()
    {
        if (string.IsNullOrWhiteSpace(ChatInput)) return;

        if (!ChatEntries.Any() && !string.IsNullOrWhiteSpace(SystemMessage))
            ChatEntries.Add((ChatGPTRole.System, SystemMessage));

        ErrorShow = false;
        ChatIsRequesting = true;

        string Input = new string(ChatInput);
        ChatInput = string.Empty;

        ChatDisabled = ChatIsRequesting || ChatIsRendering == 1 || ChatInput.Length == 0;
        StateHasChanged();

        var ChatEntry = (Role: ChatGPTRole.User, Content: Input);
        ChatEntries.Add(ChatEntry);
        try
        {
            var Completion = await OpenAIService.ChatCompletAsync(new ChatGPTRequest
                {
                    Model = OpenAIConfig.Value.APIType is APIType.Azure ? "gpt-35-turbo" : "gpt-3.5-turbo",
                    Messages = ChatEntries.Skip(ChatEntries.Count <= ChatContextLength ? 0 : ChatEntries.Count - ChatContextLength)
                        .Select(c => new ChatGPTMessage(c.Role, c.Content)).ToArray(),
                    MaxTokens = MaxTokens,
                    Temperature = Temperature,
                    TopP = TopP,
                });

            ChatEntry = (Completion.Choices[0].Message.Role, Completion.Choices[0].Message.Content);
            ChatEntries.Add(ChatEntry);

            TechDetails = $"{nameof(Choice.FinishReason)}: {Completion.Choices[0].FinishReason}, {nameof(ChatGPTResponse.Usage.PromptTokens)}: {Completion.Usage.PromptTokens}, {nameof(ChatGPTResponse.Usage.CompletionTokens)}: {Completion.Usage.CompletionTokens}";
        }
        catch (Exception ex)
        {
            ChatEntries.RemoveAt(ChatEntries.Count - 1);

            if (ChatEntries.Count == 1 && !string.IsNullOrWhiteSpace(SystemMessage))
                ChatEntries.RemoveAt(0);

            ChatInput = Input;

            ErrorShow = true;
            ErrorMessage = "Some error occurs while completing the reply. Please re-try and contact administrator if the error remains";
        }

        ChatIsRequesting = false;
        if (!ErrorShow) ChatIsRendering = 1;
        ChatDisabled = ChatIsRequesting || ChatIsRendering == 1 || ChatInput.Length == 0;
        StateHasChanged();
    }

    private void ClearChatEntries()
    {
        _ = JSRuntime.InvokeVoidAsync("stopSpeaking");

        ErrorShow = false;
        ErrorMessage = string.Empty;

        ChatEntries.Clear();

        UserUUID = Guid.NewGuid().ToString("N");
    }

    [JSInvokable(nameof(UpdateChatRenderStatus))]
    public void UpdateChatRenderStatus(int ChatRenderStatus)
    {
        ChatIsRendering = ChatRenderStatus;
        StateHasChanged();
    }

    [JSInvokable(nameof(RefreshStatus))]
    public void RefreshStatus(string VoiceInput)
    {
        ChatInput = VoiceInput;
        ChatDisabled = ChatIsRequesting || ChatIsRendering == 1 || (ChatInput).Length == 0;
        StateHasChanged();
    }
}
